{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433b25df-5b21-4924-9d2e-4d0373a8a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e47327f-1d01-48c1-a323-02cd27da0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'基准数据集.csv')\n",
    "sequences = data.Sequence\n",
    "labels = data.Label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf83714-b7f6-4d69-af6b-2df5665cb92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile('[AGCTagct]')\n",
    "\n",
    "def pre_process(text):\n",
    "    text = pat.findall(text)\n",
    "    text = [each.lower() for each in text]\n",
    "    return text\n",
    "\n",
    "x = sequences.apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e34ae4f-9a83-484e-a3c9-3155134a7ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_list = ['a', 'g', 'c', 't']\n",
    "\n",
    "word_index = {'a': 0, 'g': 1, 'c': 2, 't': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6db7aed-caa7-4c44-8268-57e9cee40e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = x.apply(lambda x: [word_index.get(word, 4) for word in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96167cd9-d302-4522-9754-7426e0873480",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len = 1200\n",
    "\n",
    "pad_text = [l + (text_len - len(l)) * [4] if len(l) < text_len else l[:text_len] for l in text]\n",
    "\n",
    "pad_text = np.array(pad_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e0828d9-6475-4e9b-bd7d-7e5bc178668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(pad_text, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d10af26-ff65-40d8-b8fc-23976bfa332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_list, label_list):\n",
    "        self.text_list = text_list\n",
    "        self.label_list = label_list\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        text = torch.LongTensor(self.text_list[index])\n",
    "        label = self.label_list[index]\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_list)\n",
    "\n",
    "train_ds = Mydataset(x_train, y_train)\n",
    "test_ds = Mydataset(x_test, y_test)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "418b3e78-63e0-47cb-bfba-7f8b2466f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=text_len) :\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0,1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d90fc5-59db-4477-af85-6237fa382cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dim = len(word_list)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pos = PositionalEncoding(one_hot_dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(one_hot_dim, nhead=2)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
    "        self.fc1 = nn.Linear(one_hot_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "           \n",
    "    def forward(self, inputs):\n",
    "        x = F.one_hot(inputs, num_classes=len(word_list)+1)\n",
    "        x = x[:, :, :-1]\n",
    "        x = x.permute(1, 0,2)\n",
    "        x = self.pos(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = torch.sum(x, dim=0)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "332a268a-5224-4f7c-aa36-58dc9f022d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = model.to('cuda')\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss = loss.to('cuda')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8eb9fd8-40b5-42be-b7f9-4de055a1c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, train_dl, test_dl):\n",
    "   \n",
    "    \"\"\"训练集\"\"\"\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_loss = 0\n",
    "    tr_TP = 0\n",
    "    tr_TN = 0\n",
    "    tr_FP = 0\n",
    "    tr_FN = 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in train_dl:\n",
    "        y = y.long()\n",
    "        x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(x)\n",
    "        loss_value = loss(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            tr_correct += (y_pred == y).sum().item()\n",
    "            tr_TP += ((y_pred == y) & (y == 1)).sum().item()\n",
    "            tr_FN += ((y_pred != y) & (y == 1)).sum().item()\n",
    "            tr_FP += ((y_pred != y) & (y == 0)).sum().item()\n",
    "            tr_TN += ((y_pred == y) & (y == 0)).sum().item()\n",
    "            tr_total += len(y)\n",
    "            tr_loss += loss_value.item()\n",
    "            \n",
    "    \"\"\"1个epoch训练结束后，计算训练集的各个指标\"\"\"\n",
    "    epoch_tr_loss = tr_loss / len(train_dl)\n",
    "    epoch_tr_accuracy = tr_correct / tr_total\n",
    "    epoch_tr_MCC = (tr_TP * tr_TN - tr_TP * tr_FN) / (math.sqrt((tr_TP + tr_FP) * (tr_TP + tr_FN) * (tr_TN + tr_FP) * (tr_TN + tr_FN)))\n",
    "    epoch_tr_SE=tr_TP/(tr_TP+tr_FN)\n",
    "    epoch_tr_SPC = tr_TN / (tr_TN + tr_FP)\n",
    "    epoch_tr_PPV= tr_TP / (tr_TP + tr_FP)\n",
    "    epoch_tr_NPV= tr_TN / (tr_TN + tr_FN)\n",
    "    epoch_tr_recall = tr_TP / (tr_TP + tr_FN)\n",
    "    epoch_tr_precision = tr_TP / (tr_TP + tr_FP)\n",
    "    epoch_tr_F1 = (2 * epoch_tr_precision * epoch_tr_recall) / (epoch_tr_precision + epoch_tr_recall)\n",
    "   \n",
    "\n",
    "    \"\"\"验证集\"\"\"\n",
    "    te_correct = 0\n",
    "    te_total = 0\n",
    "    te_loss = 0\n",
    "    te_TP = 0\n",
    "    te_TN = 0\n",
    "    te_FP = 0\n",
    "    te_FN = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dl:\n",
    "            y = y.long()\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(x)\n",
    "            loss_value = loss(y_pred, y)\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            te_correct += (y_pred == y).sum().item()\n",
    "            te_TP += ((y_pred == y) & (y == 1)).sum().item()\n",
    "            te_FN += ((y_pred != y) & (y == 1)).sum().item()\n",
    "            te_FP += ((y_pred != y) & (y == 0)).sum().item()\n",
    "            te_TN += ((y_pred == y) & (y == 0)).sum().item()\n",
    "            te_total += len(y)\n",
    "            te_loss += loss_value.item()\n",
    "        \n",
    "    \"\"\"1个epoch训练结束后，计算测试集的各个指标\"\"\"\n",
    "    epoch_te_loss = te_loss / len(test_dl)\n",
    "    epoch_te_accuracy = te_correct / te_total\n",
    "    epoch_te_MCC = (te_TP * te_TN - te_TP * te_FN) / (math.sqrt((te_TP + te_FP) * (te_TP + te_FN) * (te_TN + te_FP) * (te_TN + te_FN)))\n",
    "    epoch_te_SE=te_TP/(te_TP+te_FN)\n",
    "    epoch_te_SPC = te_TN / (te_TN + te_FP)\n",
    "    epoch_te_PPV= te_TP / (te_TP + te_FP)\n",
    "    epoch_te_NPV= te_TN / (te_TN + te_FN)\n",
    "    epoch_te_recall = te_TP / (te_TP + te_FN)\n",
    "    epoch_te_precision = te_TP / (te_TP + te_FP)\n",
    "    epoch_te_F1 = (2 * epoch_te_precision * epoch_te_recall) / (epoch_te_precision + epoch_te_recall)\n",
    "\n",
    "\n",
    "    return epoch_tr_loss, epoch_tr_accuracy, epoch_tr_MCC, epoch_tr_SE,epoch_tr_F1, epoch_tr_SPC,epoch_tr_PPV, epoch_tr_NPV,epoch_te_loss, epoch_te_accuracy, epoch_te_MCC, epoch_te_SE, epoch_te_SPC,epoch_te_PPV,epoch_te_F1,epoch_te_NPV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b46efd-494a-4c02-8f22-ce753bc3fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss = []\n",
    "tr_accuracy = []\n",
    "tr_MCC = []\n",
    "tr_SE = []\n",
    "tr_SPC = []\n",
    "tr_PPV=[]\n",
    "tr_NPV=[]\n",
    "tr_AUC=[]\n",
    "tr_F1=[]\n",
    "\n",
    "te_loss = []\n",
    "te_accuracy = []\n",
    "te_MCC = []\n",
    "te_SE = []\n",
    "te_SPC = []\n",
    "te_PPV=[]\n",
    "te_NPV=[]\n",
    "te_AUC=[]\n",
    "te_F1=[]\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d68a011e-1ccf-44b6-8dcb-45177ab95c86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.5495833333333333\n",
      "1 : 0.5070833333333333\n",
      "2 : 0.7533333333333333\n",
      "3 : 0.75625\n",
      "4 : 0.7310416666666667\n",
      "5 : 0.7354166666666667\n",
      "6 : 0.6233333333333333\n",
      "7 : 0.7210416666666667\n",
      "8 : 0.7583333333333333\n",
      "9 : 0.7358333333333333\n",
      "10 : 0.7222916666666667\n",
      "11 : 0.7691666666666667\n",
      "12 : 0.7820833333333334\n",
      "13 : 0.7604166666666666\n",
      "14 : 0.6904166666666667\n",
      "15 : 0.77125\n",
      "16 : 0.7679166666666667\n",
      "17 : 0.74375\n",
      "18 : 0.7675\n",
      "19 : 0.72625\n",
      "20 : 0.7508333333333334\n",
      "21 : 0.7547916666666666\n",
      "22 : 0.775625\n",
      "23 : 0.7845833333333333\n",
      "24 : 0.7616666666666667\n",
      "25 : 0.748125\n",
      "26 : 0.7472916666666667\n",
      "27 : 0.746875\n",
      "28 : 0.700625\n",
      "29 : 0.7529166666666667\n",
      "30 : 0.6697916666666667\n",
      "31 : 0.7135416666666666\n",
      "32 : 0.7660416666666666\n",
      "33 : 0.5891666666666666\n",
      "34 : 0.7158333333333333\n",
      "35 : 0.508125\n",
      "36 : 0.5260416666666666\n",
      "37 : 0.6383333333333333\n",
      "38 : 0.5414583333333334\n",
      "39 : 0.559375\n",
      "40 : 0.7595833333333334\n",
      "41 : 0.7327083333333333\n",
      "42 : 0.74\n",
      "43 : 0.7758333333333334\n",
      "44 : 0.77\n",
      "45 : 0.77\n",
      "46 : 0.7564583333333333\n",
      "47 : 0.7295833333333334\n",
      "48 : 0.6433333333333333\n",
      "49 : 0.785\n",
      "50 : 0.7520833333333333\n",
      "51 : 0.768125\n",
      "52 : 0.770625\n",
      "53 : 0.775625\n",
      "54 : 0.7779166666666667\n",
      "55 : 0.7520833333333333\n",
      "56 : 0.7658333333333334\n",
      "57 : 0.7666666666666667\n",
      "58 : 0.7516666666666667\n",
      "59 : 0.7491666666666666\n",
      "60 : 0.735625\n",
      "61 : 0.7472916666666667\n",
      "62 : 0.7439583333333334\n",
      "63 : 0.7522916666666667\n",
      "64 : 0.7477083333333333\n",
      "65 : 0.7483333333333333\n",
      "66 : 0.7464583333333333\n",
      "67 : 0.7447916666666666\n",
      "68 : 0.7445833333333334\n",
      "69 : 0.7535416666666667\n",
      "70 : 0.745\n",
      "71 : 0.7479166666666667\n",
      "72 : 0.76\n",
      "73 : 0.7595833333333334\n",
      "74 : 0.7658333333333334\n",
      "75 : 0.7558333333333334\n",
      "76 : 0.7670833333333333\n",
      "77 : 0.7645833333333333\n",
      "78 : 0.765625\n",
      "79 : 0.7514583333333333\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    print(f'{epoch} : ',end = '')\n",
    "    epoch_tr_loss, epoch_tr_accuracy, epoch_tr_MCC, epoch_tr_SE,epoch_tr_F1, epoch_tr_SPC,epoch_tr_PPV, epoch_tr_NPV,epoch_te_loss, epoch_te_accuracy, epoch_te_MCC, epoch_te_SE, epoch_te_SPC,epoch_te_PPV,epoch_te_F1,epoch_te_NPV= fit(model, optimizer, train_dl, test_dl)\n",
    "    \n",
    "    tr_loss.append(epoch_tr_loss)\n",
    "    tr_accuracy.append(epoch_tr_accuracy)\n",
    "    tr_MCC.append(epoch_tr_MCC)\n",
    "    tr_SE.append(epoch_tr_SE)\n",
    "    tr_SPC.append(epoch_tr_SPC)\n",
    "    tr_PPV.append(epoch_tr_PPV)\n",
    "    tr_NPV.append(epoch_tr_NPV)\n",
    "    tr_F1.append(epoch_tr_F1)\n",
    "    \"tr_AUC.append(epoch_tr_AUC)\"\n",
    "    \n",
    "    te_loss.append(epoch_te_loss)\n",
    "    te_accuracy.append(epoch_te_accuracy)\n",
    "    print(epoch_te_accuracy)\n",
    "    te_MCC.append(epoch_te_MCC)\n",
    "    te_SE.append(epoch_te_SE)\n",
    "    te_SPC.append(epoch_te_SPC)\n",
    "    te_PPV.append(epoch_te_PPV)\n",
    "    te_NPV.append(epoch_te_NPV)\n",
    "    te_F1.append(epoch_te_F1)\n",
    "    \"te_AUC.append(epoch_te_AUC)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad924a0-3183-4e11-9f90-9eb8605e0d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_name = ['loss', 'accuracy', 'MCC', 'SE', 'SPC', 'PPV', 'NPV','F1']\n",
    "\n",
    "tr_loss = pd.Series(tr_loss)\n",
    "tr_accuracy = pd.Series(tr_accuracy)\n",
    "tr_MCC = pd.Series(tr_MCC)\n",
    "tr_SE = pd.Series(tr_SE)\n",
    "tr_SPC = pd.Series(tr_SPC)\n",
    "tr_PPV = pd.Series(tr_PPV)\n",
    "tr_NPV = pd.Series(tr_NPV)\n",
    "tr_F1 = pd.Series(tr_F1)\n",
    "\n",
    "tr_result = pd.concat([tr_loss, tr_accuracy, tr_MCC, tr_SE, tr_SPC, tr_PPV, tr_NPV,tr_F1], axis=1)\n",
    "tr_result.columns = column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e0f3054-f510-490f-a938-24f67cfe41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['loss', 'accuracy', 'MCC', 'SE', 'SPC', 'PPV', 'NPV','F1']\n",
    "\n",
    "te_loss = pd.Series(te_loss)\n",
    "te_accuracy = pd.Series(te_accuracy)\n",
    "te_MCC = pd.Series(te_MCC)\n",
    "te_SE = pd.Series(te_SE)\n",
    "te_SPC = pd.Series(te_SPC)\n",
    "te_PPV = pd.Series(te_PPV)\n",
    "te_NPV = pd.Series(te_NPV)\n",
    "te_F1= pd.Series(te_F1)\n",
    "\n",
    "te_result = pd.concat([te_loss, te_accuracy, te_MCC, te_SE, te_SPC, te_PPV, te_NPV,te_F1], axis=1)\n",
    "te_result.columns = column_name\n",
    "# te_result.index = [*range(1, epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b25cc867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(te_result.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc5007e6-64fa-4589-93a8-cb27720f120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "tr_result.to_csv(r'one_hot_TF_train_result.csv')\n",
    "te_result.to_csv(r'one_hot_TF_valid_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a071b-3ad7-41d8-8eef-9182a1aeac0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
