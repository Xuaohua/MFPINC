{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433b25df-5b21-4924-9d2e-4d0373a8a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc774ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed_value = 42\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "# 如果使用GPU，还可以设置相关的随机种子\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e47327f-1d01-48c1-a323-02cd27da0568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meta</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lcl|Athaliana_AT5G45455.1</td>\n",
       "      <td>GAAATTCTTTGGAGCTCAGTGGCCCAACAAGATTATAATCCGAAAA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lcl|Athaliana_AT2G44925.1</td>\n",
       "      <td>AAGGAAAAAAAAAAAGGAATTTCGTTTCTCTTGGTGTTAAAAGGAG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lcl|Athaliana_AT3G51660.1</td>\n",
       "      <td>GTCAGATTTGAAACTCAAAGATATTATTTCAAAAATTGTTCACATC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lcl|Athaliana_AT4G06655.1</td>\n",
       "      <td>ATGAACTTGCCTTTCGATGACAAAATCAAACTCAGATTCCGACTAC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URS0000291A56_3702</td>\n",
       "      <td>GGCATCCCGTCCTTAATTGGTCC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>VIT_201s0010g02000.1</td>\n",
       "      <td>ATGGGCTCAATAGCAGGGAATTATGGTGCATGCATTTTTGTGGCAG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>VIT_208s0007g01060.2</td>\n",
       "      <td>ATGGATTCCTCTCGCGAGTTCGTCAAGGACGTCAAGCGTGTCATTG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>VIT_214s0060g01630.2</td>\n",
       "      <td>ATGGCAACTTTTGCCAAACCAGAGAATGCTTTGAAGCGAGCTGAAG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>VIT_208s0007g07570.2</td>\n",
       "      <td>ATGGGGGCGAGTCGAAAACTACAAGGCGAGATTGACAGGGTTCTGA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>VIT_204s0044g01110.1</td>\n",
       "      <td>ATGTCAAGCACAGCTGGTCAGGTTATACGCTGCAAAGCCGCGGTGG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Meta  \\\n",
       "0      lcl|Athaliana_AT5G45455.1   \n",
       "1      lcl|Athaliana_AT2G44925.1   \n",
       "2      lcl|Athaliana_AT3G51660.1   \n",
       "3      lcl|Athaliana_AT4G06655.1   \n",
       "4             URS0000291A56_3702   \n",
       "...                          ...   \n",
       "15995       VIT_201s0010g02000.1   \n",
       "15996       VIT_208s0007g01060.2   \n",
       "15997       VIT_214s0060g01630.2   \n",
       "15998       VIT_208s0007g07570.2   \n",
       "15999       VIT_204s0044g01110.1   \n",
       "\n",
       "                                                Sequence  Label  \n",
       "0      GAAATTCTTTGGAGCTCAGTGGCCCAACAAGATTATAATCCGAAAA...      1  \n",
       "1      AAGGAAAAAAAAAAAGGAATTTCGTTTCTCTTGGTGTTAAAAGGAG...      1  \n",
       "2      GTCAGATTTGAAACTCAAAGATATTATTTCAAAAATTGTTCACATC...      1  \n",
       "3      ATGAACTTGCCTTTCGATGACAAAATCAAACTCAGATTCCGACTAC...      1  \n",
       "4                                GGCATCCCGTCCTTAATTGGTCC      1  \n",
       "...                                                  ...    ...  \n",
       "15995  ATGGGCTCAATAGCAGGGAATTATGGTGCATGCATTTTTGTGGCAG...      0  \n",
       "15996  ATGGATTCCTCTCGCGAGTTCGTCAAGGACGTCAAGCGTGTCATTG...      0  \n",
       "15997  ATGGCAACTTTTGCCAAACCAGAGAATGCTTTGAAGCGAGCTGAAG...      0  \n",
       "15998  ATGGGGGCGAGTCGAAAACTACAAGGCGAGATTGACAGGGTTCTGA...      0  \n",
       "15999  ATGTCAAGCACAGCTGGTCAGGTTATACGCTGCAAAGCCGCGGTGG...      0  \n",
       "\n",
       "[16000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('基准数据集.csv')\n",
    "sequences = data.Sequence\n",
    "labels = data.Label.values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbea1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7406\n",
      "7406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meta</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zm00001d033646_T002</td>\n",
       "      <td>ATGGCCGCCGCGACAGAGAAGACGGCTGAGGACATCCGCCGCGAGC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zm00001d002782_T001</td>\n",
       "      <td>ATGGCCTCTCCTTCCCCTTCTTCCCCCGCCCGCGCCTCCGGCCGCC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zm00001d007357_T004</td>\n",
       "      <td>ATGTTTCTTAAGGAACTAGACTTACAAAAGAGTTGTGTGAAACATC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zm00001d008727_T002</td>\n",
       "      <td>ATGGCTCAGATCTTGCTCCACGGCACGCTCCACGCCACCATCTTCG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zm00001d003476_T001</td>\n",
       "      <td>ATGCACCAGGATGCACACGAGTTCTTAAATTTTCTTTTGAATGAAC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14807</th>\n",
       "      <td>URS0001BC9443_4577 Zea mays mir-393 microRNA p...</td>\n",
       "      <td>CUCCAAAGGGAUCGCAUUGAUCUAACCUGCCGAUCGACGCCGACGU...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14808</th>\n",
       "      <td>URS00021F59AE_4577 Zea mays (maize) zm00001e01...</td>\n",
       "      <td>GGGGAAAGTCTTTGACTTGCTAGCCAGCCGTAGTAGTAATAATACG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14809</th>\n",
       "      <td>URS00021F600D_4577 Zea mays (maize) zm00001e03...</td>\n",
       "      <td>ACTTACCTGGACGGGGTCGACGGGCTATCAAGAAGGCCCGTGGCCT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14810</th>\n",
       "      <td>URS00021F6599_4577 Zea mays (maize) zm00001e04...</td>\n",
       "      <td>TCTTGCCTTGCGCGATCTAAGTCTAAGGAAATACAAAAATGCGCTT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14811</th>\n",
       "      <td>URS00021F6773_4577 Zea mays (maize) zm00001e00...</td>\n",
       "      <td>ACCTGGACGTAGCGAAATCTAGATCTGCCACTGGACGCAGCGCTGC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14812 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Meta  \\\n",
       "0                                    Zm00001d033646_T002   \n",
       "1                                    Zm00001d002782_T001   \n",
       "2                                    Zm00001d007357_T004   \n",
       "3                                    Zm00001d008727_T002   \n",
       "4                                    Zm00001d003476_T001   \n",
       "...                                                  ...   \n",
       "14807  URS0001BC9443_4577 Zea mays mir-393 microRNA p...   \n",
       "14808  URS00021F59AE_4577 Zea mays (maize) zm00001e01...   \n",
       "14809  URS00021F600D_4577 Zea mays (maize) zm00001e03...   \n",
       "14810  URS00021F6599_4577 Zea mays (maize) zm00001e04...   \n",
       "14811  URS00021F6773_4577 Zea mays (maize) zm00001e00...   \n",
       "\n",
       "                                                Sequence  Label  \n",
       "0      ATGGCCGCCGCGACAGAGAAGACGGCTGAGGACATCCGCCGCGAGC...      0  \n",
       "1      ATGGCCTCTCCTTCCCCTTCTTCCCCCGCCCGCGCCTCCGGCCGCC...      0  \n",
       "2      ATGTTTCTTAAGGAACTAGACTTACAAAAGAGTTGTGTGAAACATC...      0  \n",
       "3      ATGGCTCAGATCTTGCTCCACGGCACGCTCCACGCCACCATCTTCG...      0  \n",
       "4      ATGCACCAGGATGCACACGAGTTCTTAAATTTTCTTTTGAATGAAC...      0  \n",
       "...                                                  ...    ...  \n",
       "14807  CUCCAAAGGGAUCGCAUUGAUCUAACCUGCCGAUCGACGCCGACGU...      1  \n",
       "14808  GGGGAAAGTCTTTGACTTGCTAGCCAGCCGTAGTAGTAATAATACG...      1  \n",
       "14809  ACTTACCTGGACGGGGTCGACGGGCTATCAAGAAGGCCCGTGGCCT...      1  \n",
       "14810  TCTTGCCTTGCGCGATCTAAGTCTAAGGAAATACAAAAATGCGCTT...      1  \n",
       "14811  ACCTGGACGTAGCGAAATCTAGATCTGCCACTGGACGCAGCGCTGC...      1  \n",
       "\n",
       "[14812 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_sequences_from_fasta(file_path):\n",
    "    headers = []\n",
    "    sequences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        current_header = ''\n",
    "        current_sequence = ''\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if current_header and current_sequence:\n",
    "                    headers.append(current_header)\n",
    "                    sequences.append(current_sequence)\n",
    "\n",
    "                current_header = line[1:]\n",
    "                current_sequence = ''\n",
    "            else:\n",
    "                current_sequence += line\n",
    "\n",
    "        # 处理最后一个序列\n",
    "        if current_header and current_sequence:\n",
    "            headers.append(current_header)\n",
    "            sequences.append(current_sequence)\n",
    "\n",
    "    data = {'Meta': headers, 'Sequence': sequences}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# 读取FASTA文件并提取序列\n",
    "file_path = r'C:\\Users\\26970\\Desktop\\package\\DL\\PINC-main\\DataSets\\TestSets\\\\cRNA\\Zea mays.fasta'\n",
    "datah = extract_sequences_from_fasta(file_path)\n",
    "print(datah.shape[0])\n",
    "\n",
    "file_path = r'C:\\Users\\26970\\Desktop\\package\\DL\\PINC-main\\DataSets\\TestSets\\\\ncRNA\\Zea mays.fasta'\n",
    "datah_nc = extract_sequences_from_fasta(file_path)\n",
    "print(datah_nc.shape[0])\n",
    "datah = pd.concat([datah,datah_nc]).reset_index(drop=True)\n",
    "\n",
    "pattern = r'(?:^|\\s)([^ ]+)'  # 匹配第一个空格前的非空格字符序列作为标识部分\n",
    "datah['Sequence'] = [re.search(pattern, identifier).group(1) for identifier in datah['Sequence']]\n",
    "label_data = [0] * 7406 + [1] * 7406\n",
    "\n",
    "y = pd.DataFrame(label_data, columns=['Label'])\n",
    "datah.reset_index(drop=True, inplace=True)\n",
    "datah = datah.join(y)\n",
    "\n",
    "sequences_te = datah.Sequence\n",
    "labels_te = datah.Label.values\n",
    "\n",
    "datah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf83714-b7f6-4d69-af6b-2df5665cb92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile('[AGCTagct]')\n",
    "\n",
    "def pre_process(text):\n",
    "    text = pat.findall(text)\n",
    "    text = [each.lower() for each in text]\n",
    "    return text\n",
    "\n",
    "x = sequences.apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0a1b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [a, t, g, g, c, c, g, c, c, g, c, g, a, c, a, ...\n",
       "1        [a, t, g, g, c, c, t, c, t, c, c, t, t, c, c, ...\n",
       "2        [a, t, g, t, t, t, c, t, t, a, a, g, g, a, a, ...\n",
       "3        [a, t, g, g, c, t, c, a, g, a, t, c, t, t, g, ...\n",
       "4        [a, t, g, c, a, c, c, a, g, g, a, t, g, c, a, ...\n",
       "                               ...                        \n",
       "14807    [c, c, c, a, a, a, g, g, g, a, c, g, c, a, g, ...\n",
       "14808    [g, g, g, g, a, a, a, g, t, c, t, t, t, g, a, ...\n",
       "14809    [a, c, t, t, a, c, c, t, g, g, a, c, g, g, g, ...\n",
       "14810    [t, c, t, t, g, c, c, t, t, g, c, g, c, g, a, ...\n",
       "14811    [a, c, c, t, g, g, a, c, g, t, a, g, c, g, a, ...\n",
       "Name: Sequence, Length: 14812, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_te = sequences_te.apply(pre_process)\n",
    "x_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e52c27-228f-4395-8ae6-554e36773674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'c': 2, 't': 3, 'g': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set = set()\n",
    "\n",
    "for lst in x:\n",
    "    for word in lst:\n",
    "        word_set.add(word)\n",
    "\n",
    "word_list = list(word_set)\n",
    "word_index = dict([(each, word_list.index(each) + 1) for each in word_list])\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43fd8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'c': 2, 't': 3, 'g': 4}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set_te = set()\n",
    "\n",
    "for lst_te in x_te:\n",
    "    for word_te in lst_te:\n",
    "        word_set_te.add(word_te)\n",
    "        \n",
    "word_list_te = list(word_set_te)\n",
    "word_index_te = dict([(each_te, word_list_te.index(each_te) + 1) for each_te in word_list_te])\n",
    "word_index_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6db7aed-caa7-4c44-8268-57e9cee40e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = x.apply(lambda x: [word_index.get(word, 0) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8900972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [1, 3, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 1, 2, 1, ...\n",
       "1        [1, 3, 4, 4, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 2, ...\n",
       "2        [1, 3, 4, 3, 3, 3, 2, 3, 3, 1, 1, 4, 4, 1, 1, ...\n",
       "3        [1, 3, 4, 4, 2, 3, 2, 1, 4, 1, 3, 2, 3, 3, 4, ...\n",
       "4        [1, 3, 4, 2, 1, 2, 2, 1, 4, 4, 1, 3, 4, 2, 1, ...\n",
       "                               ...                        \n",
       "14807    [2, 2, 2, 1, 1, 1, 4, 4, 4, 1, 2, 4, 2, 1, 4, ...\n",
       "14808    [4, 4, 4, 4, 1, 1, 1, 4, 3, 2, 3, 3, 3, 4, 1, ...\n",
       "14809    [1, 2, 3, 3, 1, 2, 2, 3, 4, 4, 1, 2, 4, 4, 4, ...\n",
       "14810    [3, 2, 3, 3, 4, 2, 2, 3, 3, 4, 2, 4, 2, 4, 1, ...\n",
       "14811    [1, 2, 2, 3, 4, 4, 1, 2, 4, 3, 1, 4, 2, 4, 1, ...\n",
       "Name: Sequence, Length: 14812, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_te = x_te.apply(lambda x_te: [word_index_te.get(word, 0) for word in x_te])\n",
    "text_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96167cd9-d302-4522-9754-7426e0873480",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len = 1000\n",
    "\n",
    "pad_text = [l + (text_len - len(l)) * [0] if len(l) < text_len else l[:text_len] for l in text]\n",
    "\n",
    "pad_text = np.array(pad_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed493eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 4, ..., 2, 3, 4],\n",
       "       [1, 3, 4, ..., 0, 0, 0],\n",
       "       [1, 3, 4, ..., 1, 4, 4],\n",
       "       ...,\n",
       "       [1, 2, 3, ..., 0, 0, 0],\n",
       "       [3, 2, 3, ..., 0, 0, 0],\n",
       "       [1, 2, 2, ..., 3, 3, 2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len = 1000\n",
    "\n",
    "pad_text_te = [l + (text_len - len(l)) * [0] if len(l) < text_len else l[:text_len] for l in text_te]\n",
    "\n",
    "pad_text_te = np.array(pad_text_te)\n",
    "pad_text_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0828d9-6475-4e9b-bd7d-7e5bc178668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(pad_text, labels, test_size=0.3)\n",
    "# x_train = pad_text\n",
    "# x_test = pad_text_te\n",
    "# y_train = labels\n",
    "# y_test = labels_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d10af26-ff65-40d8-b8fc-23976bfa332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_list, label_list):\n",
    "        self.text_list = text_list\n",
    "        self.label_list = label_list\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        text = torch.LongTensor(self.text_list[index])\n",
    "        label = self.label_list[index]\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_list)\n",
    "\n",
    "train_ds = Mydataset(x_train, y_train)\n",
    "test_ds = Mydataset(x_test, y_test)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "418b3e78-63e0-47cb-bfba-7f8b2466f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=text_len) :\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len,dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0,1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49d90fc5-59db-4477-af85-6237fa382cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_dim: 50\n"
     ]
    }
   ],
   "source": [
    "# embed_dim = 2 ** (int(np.log2(len(word_list) ** 0.25)) + 2)  # 经验值\n",
    "\n",
    "embedding_dim = 50\n",
    "print('embedding_dim:', embedding_dim)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.em = nn.Embedding(len(word_list) + 1, embedding_dim)  # 对0也需要编码\n",
    "        self.pos = PositionalEncoding(embedding_dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(embedding_dim, nhead=5)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "           \n",
    "    def forward(self, inputs):\n",
    "        x = self.em(inputs)\n",
    "        x = self.pos(x)\n",
    "        x = x.float()\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = torch.sum(x, dim=0)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "332a268a-5224-4f7c-aa36-58dc9f022d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = model.to('cuda')\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss = loss.to('cuda')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8eb9fd8-40b5-42be-b7f9-4de055a1c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, train_dl, test_dl):\n",
    "    \n",
    "    tr_correct = 0  # 预测正确的个数\n",
    "    tr_total = 0  # 总样本数\n",
    "    tr_loss = 0\n",
    "    tr_TP = 0\n",
    "    tr_TN = 0\n",
    "    tr_FP = 0\n",
    "    tr_FN = 0\n",
    "    \n",
    "    model.train()  # 训练模式\n",
    "    for x, y in train_dl:\n",
    "        x = x.permute(1, 0)\n",
    "        x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(x)\n",
    "        loss_value = loss(y_pred, y)\n",
    "        #flood=(loss_value - 0.002).abs() + 0.002  # 洪泛函数：防止过拟合\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred, dim=1)  # 在预测结果 y_pred 的每个样本上找到具有最大值的索引\n",
    "            tr_correct += (y_pred == y).sum().item()\n",
    "            tr_TP += ((y_pred == y) & (y == 1)).sum().item()\n",
    "            tr_FN += ((y_pred != y) & (y == 1)).sum().item()\n",
    "            tr_FP += ((y_pred != y) & (y == 0)).sum().item()\n",
    "            tr_TN += ((y_pred == y) & (y == 0)).sum().item()\n",
    "            tr_total += len(y)\n",
    "            tr_loss += loss_value.item()  # 最后的loss还要除以batch数\n",
    "            \n",
    "    \"\"\"1个epoch训练结束后，计算训练集的各个指标\"\"\"\n",
    "    epoch_tr_loss = tr_loss / len(train_dl)\n",
    "    epoch_tr_accuracy = tr_correct / tr_total\n",
    "    epoch_tr_MCC = (tr_TP * tr_TN - tr_TP * tr_FN) / (math.sqrt((tr_TP + tr_FP) * (tr_TP + tr_FN) * (tr_TN + tr_FP) * (tr_TN + tr_FN)+ 0.01)) \n",
    "    epoch_tr_SE=tr_TP/(tr_TP+tr_FN+ 0.01) \n",
    "    epoch_tr_SPC = tr_TN / (tr_TN + tr_FP+ 0.01) \n",
    "    epoch_tr_PPV= tr_TP / (tr_TP + tr_FP+ 0.01) \n",
    "    epoch_tr_NPV= tr_TN / (tr_TN + tr_FN+ 0.01) \n",
    "    epoch_tr_recall = tr_TP / (tr_TP + tr_FN+ 0.01) \n",
    "    epoch_tr_precision = tr_TP / (tr_TP + tr_FP+ 0.01) \n",
    "    epoch_tr_F1 = (2 * epoch_tr_precision * epoch_tr_recall) / (epoch_tr_precision + epoch_tr_recall+ 0.01) \n",
    "    \n",
    "    te_correct = 0  # 预测正确的个数\n",
    "    te_total = 0  # 总样本数\n",
    "    te_loss = 0\n",
    "    te_TP = 0\n",
    "    te_TN = 0\n",
    "    te_FP = 0\n",
    "    te_FN = 0\n",
    "    \n",
    "    model.eval()  # 评估模式\n",
    "    with torch.no_grad():# 是一个上下文管理器，用于在块中禁用梯度计算，以减少内存使用并加快计算速度\n",
    "        for x, y in test_dl:\n",
    "            x = x.permute(1, 0)\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(x)\n",
    "            loss_value = loss(y_pred, y)\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            te_correct += (y_pred == y).sum().item()\n",
    "            te_TP += ((y_pred == y) & (y == 1)).sum().item()\n",
    "            te_FN += ((y_pred != y) & (y == 1)).sum().item()\n",
    "            te_FP += ((y_pred != y) & (y == 0)).sum().item()\n",
    "            te_TN += ((y_pred == y) & (y == 0)).sum().item()\n",
    "            te_total += len(y)\n",
    "            te_loss += loss_value.item()\n",
    "        \n",
    "    \"\"\"1个epoch训练结束后，计算测试集的各个指标\"\"\"\n",
    "    epoch_te_loss = te_loss / len(test_dl)\n",
    "    epoch_te_accuracy = te_correct / te_total\n",
    "    epoch_te_MCC = (te_TP * te_TN - te_TP * te_FN) / (math.sqrt((te_TP + te_FP) * (te_TP + te_FN) * (te_TN + te_FP) * (te_TN + te_FN)+ 0.01)) \n",
    "    epoch_te_SE=te_TP/(te_TP+te_FN  + 0.01)\n",
    "    epoch_te_SPC = te_TN / (te_TN + te_FP + 0.01) \n",
    "    epoch_te_PPV= te_TP / (te_TP + te_FP + 0.01) \n",
    "    epoch_te_NPV= te_TN / (te_TN + te_FN + 0.01)\n",
    "    epoch_te_recall = te_TP / (te_TP + te_FN + 0.01) \n",
    "    epoch_te_precision = te_TP / (te_TP + te_FP + 0.01)\n",
    "    epoch_te_F1 = (2 * epoch_te_precision * epoch_te_recall) / (epoch_te_precision + epoch_te_recall + 0.01)\n",
    "\n",
    "    return epoch_tr_loss, epoch_tr_accuracy, epoch_tr_MCC, epoch_tr_SE,epoch_tr_F1, epoch_tr_SPC,epoch_tr_PPV, epoch_tr_NPV,epoch_te_loss, epoch_te_accuracy, epoch_te_MCC, epoch_te_SE, epoch_te_SPC,epoch_te_PPV,epoch_te_F1,epoch_te_NPV\n",
    "#     return epoch_tr_loss, epoch_tr_accuracy,epoch_te_loss, epoch_te_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65b46efd-494a-4c02-8f22-ce753bc3fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss = []\n",
    "tr_accuracy = []\n",
    "tr_MCC = []\n",
    "tr_SE = []\n",
    "tr_SPC = []\n",
    "tr_PPV=[]\n",
    "tr_NPV=[]\n",
    "tr_AUC=[]\n",
    "tr_F1=[]\n",
    "\n",
    "te_loss = []\n",
    "te_accuracy = []\n",
    "te_MCC = []\n",
    "te_SE = []\n",
    "te_SPC = []\n",
    "te_PPV=[]\n",
    "te_NPV=[]\n",
    "te_AUC=[]\n",
    "te_F1=[]\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1ec7f53",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.8085416666666667\n",
      "1 : 0.575\n",
      "2 : 0.8110416666666667\n",
      "3 : 0.6247916666666666\n",
      "4 : 0.8291666666666667\n",
      "5 : 0.7725\n",
      "6 : 0.8197916666666667\n",
      "7 : 0.8122916666666666\n",
      "8 : 0.8352083333333333\n",
      "9 : 0.7077083333333334\n",
      "10 : 0.783125\n",
      "11 : 0.7779166666666667\n",
      "12 : 0.77875\n",
      "13 : 0.8610416666666667\n",
      "14 : 0.8352083333333333\n",
      "15 : 0.7439583333333334\n",
      "16 : 0.7770833333333333\n",
      "17 : 0.8535416666666666\n",
      "18 : 0.8297916666666667\n",
      "19 : 0.506875\n",
      "20 : 0.6233333333333333\n",
      "21 : 0.84875\n",
      "22 : 0.8660416666666667\n",
      "23 : 0.5541666666666667\n",
      "24 : 0.700625\n",
      "25 : 0.671875\n",
      "26 : 0.875625\n",
      "27 : 0.873125\n",
      "28 : 0.8597916666666666\n",
      "29 : 0.8808333333333334\n",
      "30 : 0.876875\n",
      "31 : 0.8825\n",
      "32 : 0.8877083333333333\n",
      "33 : 0.8377083333333334\n",
      "34 : 0.8604166666666667\n",
      "35 : 0.874375\n",
      "36 : 0.8864583333333333\n",
      "37 : 0.8777083333333333\n",
      "38 : 0.9029166666666667\n",
      "39 : 0.8954166666666666\n",
      "40 : 0.8979166666666667\n",
      "41 : 0.8864583333333333\n",
      "42 : 0.8722916666666667\n",
      "43 : 0.9075\n",
      "44 : 0.8966666666666666\n",
      "45 : 0.8729166666666667\n",
      "46 : "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs): \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m'\u001b[39m,end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     epoch_tr_loss, epoch_tr_accuracy, epoch_tr_MCC, epoch_tr_SE,epoch_tr_F1, epoch_tr_SPC,epoch_tr_PPV, epoch_tr_NPV,epoch_te_loss, epoch_te_accuracy, epoch_te_MCC, epoch_te_SE, epoch_te_SPC,epoch_te_PPV,epoch_te_F1,epoch_te_NPV\u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     tr_loss\u001b[38;5;241m.\u001b[39mappend(epoch_tr_loss)\n\u001b[0;32m      8\u001b[0m     tr_accuracy\u001b[38;5;241m.\u001b[39mappend(epoch_tr_accuracy)\n",
      "Cell \u001b[1;32mIn[18], line 19\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, optimizer, train_dl, test_dl)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#flood=(loss_value - 0.002).abs() + 0.002  # 洪泛函数：防止过拟合\u001b[39;00m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mloss_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mD:\\toolsMore\\Anaconda\\anaconda\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\toolsMore\\Anaconda\\anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    print(f'{epoch} : ',end = '')\n",
    "    epoch_tr_loss, epoch_tr_accuracy, epoch_tr_MCC, epoch_tr_SE,epoch_tr_F1, epoch_tr_SPC,epoch_tr_PPV, epoch_tr_NPV,epoch_te_loss, epoch_te_accuracy, epoch_te_MCC, epoch_te_SE, epoch_te_SPC,epoch_te_PPV,epoch_te_F1,epoch_te_NPV= fit(model, optimizer, train_dl, test_dl)\n",
    "    \n",
    "    tr_loss.append(epoch_tr_loss)\n",
    "    tr_accuracy.append(epoch_tr_accuracy)\n",
    "    tr_MCC.append(epoch_tr_MCC)\n",
    "    tr_SE.append(epoch_tr_SE)\n",
    "    tr_SPC.append(epoch_tr_SPC)\n",
    "    tr_PPV.append(epoch_tr_PPV)\n",
    "    tr_NPV.append(epoch_tr_NPV)\n",
    "    tr_F1.append(epoch_tr_F1)\n",
    "    \"tr_AUC.append(epoch_tr_AUC)\"\n",
    "    \n",
    "    te_loss.append(epoch_te_loss)\n",
    "    te_accuracy.append(epoch_te_accuracy)\n",
    "    print(epoch_te_accuracy)\n",
    "    te_MCC.append(epoch_te_MCC)\n",
    "    te_SE.append(epoch_te_SE)\n",
    "    te_SPC.append(epoch_te_SPC)\n",
    "    te_PPV.append(epoch_te_PPV)\n",
    "    te_NPV.append(epoch_te_NPV)\n",
    "    te_F1.append(epoch_te_F1)\n",
    "    \"te_AUC.append(epoch_te_AUC)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad924a0-3183-4e11-9f90-9eb8605e0d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_name = ['loss', 'accuracy', 'MCC', 'SE', 'SPC', 'PPV', 'NPV','F1']\n",
    "\n",
    "tr_loss = pd.Series(tr_loss,dtype='float64')\n",
    "tr_accuracy = pd.Series(tr_accuracy,dtype='float64')\n",
    "tr_MCC = pd.Series(tr_MCC,dtype='float64')\n",
    "tr_SE = pd.Series(tr_SE,dtype='float64')\n",
    "tr_SPC = pd.Series(tr_SPC,dtype='float64')\n",
    "tr_PPV = pd.Series(tr_PPV,dtype='float64')\n",
    "tr_NPV = pd.Series(tr_NPV,dtype='float64')\n",
    "tr_F1 = pd.Series(tr_F1,dtype='float64')\n",
    "\n",
    "tr_result = pd.concat([tr_loss, tr_accuracy, tr_MCC, tr_SE, tr_SPC, tr_PPV, tr_NPV,tr_F1], axis=1)\n",
    "tr_result.columns = column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f3054-f510-490f-a938-24f67cfe41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['loss', 'accuracy', 'MCC', 'SE', 'SPC', 'PPV', 'NPV','F1']\n",
    "\n",
    "te_loss = pd.Series(te_loss)\n",
    "te_accuracy = pd.Series(te_accuracy)\n",
    "te_MCC = pd.Series(te_MCC)\n",
    "te_SE = pd.Series(te_SE)\n",
    "te_SPC = pd.Series(te_SPC)\n",
    "te_PPV = pd.Series(te_PPV)\n",
    "te_NPV = pd.Series(te_NPV)\n",
    "te_F1= pd.Series(te_F1)\n",
    "\n",
    "te_result = pd.concat([te_loss, te_accuracy, te_MCC, te_SE, te_SPC, te_PPV, te_NPV,te_F1], axis=1)\n",
    "te_result.columns = column_name\n",
    "#te_result.index = [*range(1, epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b9818",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max(te_result.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59005501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "tr_result.to_csv(r'./调参前后/Word_embedding_TF_train.csv')\n",
    "te_result.to_csv(r'./调参前后/Word_embedding_TF_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    print(f'{epoch} : ',end = '')\n",
    "    epoch_tr_loss, epoch_tr_accuracy, epoch_tr_MCC, epoch_tr_SE,epoch_tr_F1, epoch_tr_SPC,epoch_tr_PPV, epoch_tr_NPV,epoch_te_loss, epoch_te_accuracy, epoch_te_MCC, epoch_te_SE, epoch_te_SPC,epoch_te_PPV,epoch_te_F1,epoch_te_NPV= fit(model, optimizer, train_dl, test_dl)\n",
    "    \n",
    "    tr_loss.append(epoch_tr_loss)\n",
    "    tr_accuracy.append(epoch_tr_accuracy)\n",
    "    tr_MCC.append(epoch_tr_MCC)\n",
    "    tr_SE.append(epoch_tr_SE)\n",
    "    tr_SPC.append(epoch_tr_SPC)\n",
    "    tr_PPV.append(epoch_tr_PPV)\n",
    "    tr_NPV.append(epoch_tr_NPV)\n",
    "    tr_F1.append(epoch_tr_F1)\n",
    "    \"tr_AUC.append(epoch_tr_AUC)\"\n",
    "    \n",
    "    te_loss.append(epoch_te_loss)\n",
    "    te_accuracy.append(epoch_te_accuracy)\n",
    "    print(epoch_te_accuracy)\n",
    "    te_MCC.append(epoch_te_MCC)\n",
    "    te_SE.append(epoch_te_SE)\n",
    "    te_SPC.append(epoch_te_SPC)\n",
    "    te_PPV.append(epoch_te_PPV)\n",
    "    te_NPV.append(epoch_te_NPV)\n",
    "    te_F1.append(epoch_te_F1)\n",
    "    \"te_AUC.append(epoch_te_AUC)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "285f982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.90625\n",
      "loss : 0.2586334294546396\n",
      "mcc : 0.7582582397925111\n",
      "se : 1.01\n",
      "spc : 0.99999584891719\n",
      "ppv : 0.9765166524257988\n",
      "npv : 0.9699948947637118\n",
      "f1 : 0.9032649047711644\n"
     ]
    }
   ],
   "source": [
    "te_data = pd.read_csv(r'./batch-size/Word_embedding_TF_valid-8.csv')\n",
    "te_data_acc = max(te_data.accuracy)\n",
    "print(f'acc : {te_data_acc}')\n",
    "print(f'loss : {min(te_data.loss)}')\n",
    "print(f'mcc : {max(te_data.MCC)}')\n",
    "print(f'se : {max(te_data.SE)}')\n",
    "print(f'spc : {max(te_data.SPC)}')\n",
    "print(f'ppv : {max(te_data.PPV)}')\n",
    "print(f'npv : {max(te_data.NPV)}')\n",
    "print(f'f1 : {max(te_data.F1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
