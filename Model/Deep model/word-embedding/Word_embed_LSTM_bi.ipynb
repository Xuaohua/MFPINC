{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611e58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456949ce",
   "metadata": {},
   "source": [
    "## 1.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec88b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'基准数据集.csv')  # 导入数据\n",
    "sequences = data.Sequence  # 序列\n",
    "labels = data.Label.values  # 标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2556c723",
   "metadata": {},
   "source": [
    "## 2.预处理：每个字母为单个字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0514be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile('[AGCTagct]')\n",
    "\n",
    "def pre_process(text):\n",
    "    text = pat.findall(text)\n",
    "    text = [each.lower() for each in text]\n",
    "    return text\n",
    "\n",
    "x = sequences.apply(pre_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e66fa0",
   "metadata": {},
   "source": [
    "## 3.创建词典：word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c18304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set()  # 初始化\n",
    "\n",
    "for lst in x:\n",
    "    for word in lst:\n",
    "        word_set.add(word)\n",
    "\n",
    "word_list = list(word_set)\n",
    "word_index = dict([(each, word_list.index(each) + 1) for each in word_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c0c99d",
   "metadata": {},
   "source": [
    "## 4.将序列中的字母转换为数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580d0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = x.apply(lambda x: [word_index.get(word, 0) for word in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165486d",
   "metadata": {},
   "source": [
    "## 5.固定序列的长度，进行截断或填充操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02dde545",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len = 1200  # 长度固定为1200\n",
    "\n",
    "pad_text = [l + (text_len - len(l)) * [0] if len(l) < text_len else l[:text_len] for l in text]  # 用0填充或者截断\n",
    "\n",
    "pad_text = np.array(pad_text)  # 转为数组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6832b43e",
   "metadata": {},
   "source": [
    "## 6.划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c64c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(pad_text, labels, test_size=0.3)  # 默认采用分层抽样构建训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87480556",
   "metadata": {},
   "source": [
    "## 7.构建数据迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c78c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_list, label_list):  # 将序列和标签保存在类属性中\n",
    "        self.text_list = text_list\n",
    "        self.label_list = label_list\n",
    "    \n",
    "    def __getitem__(self,index):  # 索引序列和标签\n",
    "        text = torch.LongTensor(self.text_list[index])  # Tensor中的元素转换为64位整型\n",
    "        label = self.label_list[index]\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_list)  # 返回序列数\n",
    "\n",
    "train_ds = Mydataset(x_train, y_train)  # 将训练集单独存储\n",
    "test_ds = Mydataset(x_test, y_test)  # 将测试集单独存储\n",
    "\n",
    "batch_size = 32  # 批量大小\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a38d2",
   "metadata": {},
   "source": [
    "## 8.定义网络架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14311682",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 24  # 嵌入维度\n",
    "hidden_size = 20  # 隐藏层单元数\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, word_list, embed_dim, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.em = nn.Embedding(len(word_list) + 1, embed_dim)   \n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_size,bidirectional=True)     \n",
    "        self.fc1 = nn.Linear(2*hidden_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        bz = inputs.shape[1]\n",
    "        h0 = torch.zeros((2, bz, hidden_size)).to('cuda')\n",
    "        c0 = torch.zeros((2, bz, hidden_size)).to('cuda')\n",
    "        x = self.em(inputs)\n",
    "        r_o, _ = self.rnn(x, (h0, c0))\n",
    "        r_o = r_o[-1]\n",
    "        x = F.dropout(F.relu(self.fc1(r_o)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac25c56",
   "metadata": {},
   "source": [
    "## 9.定义交叉熵损失函数和Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eff2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(word_list, embed_dim, hidden_size)  # 实例化\n",
    "model = model.to('cuda')  # 将模型放到gpu上\n",
    "\n",
    "loss = nn.CrossEntropyLoss()  # 默认求每个batch下的平均损失\n",
    "loss = loss.to('cuda')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2898a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_tr_y=[]\n",
    "epoch_tr_y_pre=[]\n",
    "epoch_tr_AUC=[]\n",
    "epoch_te_AUC=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f86ee3",
   "metadata": {},
   "source": [
    "## 10.定义训练函数，并计算评价指标(1个epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8ed082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, train_dl, test_dl):\n",
    "    \n",
    "    tr_correct = 0  # 预测正确的个数\n",
    "    tr_total = 0  # 总样本数\n",
    "    tr_loss = 0\n",
    "    tr_TP = 0\n",
    "    tr_TN = 0\n",
    "    tr_FP = 0\n",
    "    tr_FN = 0\n",
    "    \n",
    "    model.train()  # 训练模式\n",
    "    for x, y in train_dl:\n",
    "        x = x.permute(1, 0)\n",
    "        x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(x)\n",
    "        loss_value = loss(y_pred, y)\n",
    "        #flood=(loss_value - 0.002).abs() + 0.002  # 洪泛函数：防止过拟合\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            tr_correct += (y_pred == y).sum().item()\n",
    "            tr_TP += ((y_pred == y) & (y == 1)).sum().item()\n",
    "            tr_FN += ((y_pred != y) & (y == 1)).sum().item()\n",
    "            tr_FP += ((y_pred != y) & (y == 0)).sum().item()\n",
    "            tr_TN += ((y_pred == y) & (y == 0)).sum().item()\n",
    "            tr_total += len(y)\n",
    "            tr_loss += loss_value.item()  # 最后的loss还要除以batch数\n",
    "            \n",
    "    \"\"\"1个epoch训练结束后，计算训练集的各个指标\"\"\"\n",
    "    epoch_tr_loss = tr_loss / len(train_dl)\n",
    "    epoch_tr_accuracy = tr_correct / tr_total\n",
    "    epoch_tr_MCC = (tr_TP * tr_TN - tr_TP * tr_FN) / (math.sqrt((tr_TP + tr_FP) * (tr_TP + tr_FN) * (tr_TN + tr_FP) * (tr_TN + tr_FN)))\n",
    "    epoch_tr_SE=tr_TP/(tr_TP+tr_FN)\n",
    "    epoch_tr_SPC = tr_TN / (tr_TN + tr_FP)\n",
    "    epoch_tr_PPV= tr_TP / (tr_TP + tr_FP)\n",
    "    epoch_tr_NPV= tr_TN / (tr_TN + tr_FN)\n",
    "    epoch_tr_recall = tr_TP / (tr_TP + tr_FN)\n",
    "    epoch_tr_precision = tr_TP / (tr_TP + tr_FP)\n",
    "    epoch_tr_F1 = (2 * epoch_tr_precision * epoch_tr_recall) / (epoch_tr_precision + epoch_tr_recall)\n",
    "    \n",
    "    \n",
    "    te_correct = 0  # 预测正确的个数\n",
    "    te_total = 0  # 总样本数\n",
    "    te_loss = 0\n",
    "    te_TP = 0\n",
    "    te_TN = 0\n",
    "    te_FP = 0\n",
    "    te_FN = 0\n",
    "    \n",
    "    model.eval()  # 评估模式\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dl:\n",
    "            x = x.permute(1, 0)\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(x)\n",
    "            loss_value = loss(y_pred, y)\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            te_correct += (y_pred == y).sum().item()\n",
    "            te_TP += ((y_pred == y) & (y == 1)).sum().item()\n",
    "            te_FN += ((y_pred != y) & (y == 1)).sum().item()\n",
    "            te_FP += ((y_pred != y) & (y == 0)).sum().item()\n",
    "            te_TN += ((y_pred == y) & (y == 0)).sum().item()\n",
    "            te_total += len(y)\n",
    "            te_loss += loss_value.item()\n",
    "        \n",
    "    \"\"\"1个epoch训练结束后，计算测试集的各个指标\"\"\"\n",
    "    epoch_te_loss = te_loss / len(test_dl)\n",
    "    epoch_te_accuracy = te_correct / te_total\n",
    "    epoch_te_MCC = (te_TP * te_TN - te_TP * te_FN) / (math.sqrt((te_TP + te_FP) * (te_TP + te_FN) * (te_TN + te_FP) * (te_TN + te_FN)))\n",
    "    epoch_te_SE=te_TP/(te_TP+te_FN)\n",
    "    epoch_te_SPC = te_TN / (te_TN + te_FP)\n",
    "    epoch_te_PPV= te_TP / (te_TP + te_FP)\n",
    "    epoch_te_NPV= te_TN / (te_TN + te_FN)\n",
    "    epoch_te_recall = te_TP / (te_TP + te_FN)\n",
    "    epoch_te_precision = te_TP / (te_TP + te_FP)\n",
    "    epoch_te_F1 = (2 * epoch_te_precision * epoch_te_recall) / (epoch_te_precision + epoch_te_recall)\n",
    "\n",
    "\n",
    "    return epoch_tr_loss, epoch_tr_accuracy, epoch_tr_MCC, epoch_tr_SE,epoch_tr_F1, epoch_tr_SPC,epoch_tr_PPV, epoch_tr_NPV,epoch_te_loss, epoch_te_accuracy, epoch_te_MCC, epoch_te_SE, epoch_te_SPC,epoch_te_PPV,epoch_te_F1,epoch_te_NPV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d4134",
   "metadata": {},
   "source": [
    "## 11.初始化，用于存储各指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bb2de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss = []\n",
    "tr_accuracy = []\n",
    "tr_MCC = []\n",
    "tr_SE = []\n",
    "tr_SPC = []\n",
    "tr_PPV=[]\n",
    "tr_NPV=[]\n",
    "tr_AUC=[]\n",
    "tr_F1=[]\n",
    "\n",
    "te_loss = []\n",
    "te_accuracy = []\n",
    "te_MCC = []\n",
    "te_SE = []\n",
    "te_SPC = []\n",
    "te_PPV=[]\n",
    "te_NPV=[]\n",
    "te_AUC=[]\n",
    "te_F1=[]\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb219631",
   "metadata": {},
   "source": [
    "## 12.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de213b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.6845833333333333\n",
      "1 : 0.6822916666666666\n",
      "2 : 0.6854166666666667\n",
      "3 : 0.6858333333333333\n",
      "4 : 0.6910416666666667\n",
      "5 : 0.6879166666666666\n",
      "6 : 0.6952083333333333\n",
      "7 : 0.68125\n",
      "8 : 0.6775\n",
      "9 : 0.681875\n",
      "10 : 0.6785416666666667\n",
      "11 : 0.67875\n",
      "12 : 0.6791666666666667\n",
      "13 : 0.679375\n",
      "14 : 0.679375\n",
      "15 : 0.679375\n",
      "16 : 0.6795833333333333\n",
      "17 : 0.6802083333333333\n",
      "18 : 0.6804166666666667\n",
      "19 : 0.680625\n",
      "20 : 0.6802083333333333\n",
      "21 : 0.6814583333333334\n",
      "22 : 0.6802083333333333\n",
      "23 : 0.6852083333333333\n",
      "24 : 0.6820833333333334\n",
      "25 : 0.685625\n",
      "26 : 0.6827083333333334\n",
      "27 : 0.6835416666666667\n",
      "28 : 0.6845833333333333\n",
      "29 : 0.69\n",
      "30 : 0.689375\n",
      "31 : 0.6954166666666667\n",
      "32 : 0.6752083333333333\n",
      "33 : 0.669375\n",
      "34 : 0.6835416666666667\n",
      "35 : 0.6795833333333333\n",
      "36 : 0.6825\n",
      "37 : 0.69375\n",
      "38 : 0.6666666666666666\n",
      "39 : 0.68125\n",
      "40 : 0.688125\n",
      "41 : 0.6797916666666667\n",
      "42 : 0.6864583333333333\n",
      "43 : 0.6966666666666667\n",
      "44 : 0.6902083333333333\n",
      "45 : 0.6841666666666667\n",
      "46 : 0.68\n",
      "47 : 0.6577083333333333\n",
      "48 : 0.68125\n",
      "49 : 0.6814583333333334\n",
      "50 : 0.6825\n",
      "51 : 0.68625\n",
      "52 : 0.6877083333333334\n",
      "53 : 0.69125\n",
      "54 : 0.6860416666666667\n",
      "55 : 0.6810416666666667\n",
      "56 : 0.68625\n",
      "57 : 0.6845833333333333\n",
      "58 : 0.6858333333333333\n",
      "59 : 0.6879166666666666\n",
      "60 : 0.5210416666666666\n",
      "61 : 0.6777083333333334\n",
      "62 : 0.6779166666666666\n",
      "63 : 0.676875\n",
      "64 : 0.6783333333333333\n",
      "65 : 0.6764583333333334\n",
      "66 : 0.678125\n",
      "67 : 0.6777083333333334\n",
      "68 : 0.6777083333333334\n",
      "69 : 0.6785416666666667\n",
      "70 : 0.679375\n",
      "71 : 0.678125\n",
      "72 : 0.6777083333333334\n",
      "73 : 0.678125\n",
      "74 : 0.6777083333333334\n",
      "75 : 0.6777083333333334\n",
      "76 : 0.6804166666666667\n",
      "77 : 0.6789583333333333\n",
      "78 : 0.6808333333333333\n",
      "79 : 0.6820833333333334\n",
      "80 : 0.6825\n",
      "81 : 0.6827083333333334\n",
      "82 : 0.6764583333333334\n",
      "83 : 0.6820833333333334\n",
      "84 : 0.6825\n",
      "85 : 0.6864583333333333\n",
      "86 : 0.6866666666666666\n",
      "87 : 0.6858333333333333\n",
      "88 : 0.6833333333333333\n",
      "89 : 0.668125\n",
      "90 : 0.6845833333333333\n",
      "91 : 0.6889583333333333\n",
      "92 : 0.69625\n",
      "93 : 0.6902083333333333\n",
      "94 : 0.6875\n",
      "95 : 0.6910416666666667\n",
      "96 : 0.689375\n",
      "97 : 0.679375\n",
      "98 : 0.6802083333333333\n",
      "99 : 0.6802083333333333\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    print(f'{epoch} : ',end = '')\n",
    "    epoch_tr_loss, epoch_tr_accuracy, epoch_tr_MCC, epoch_tr_SE,epoch_tr_F1, epoch_tr_SPC,epoch_tr_PPV, epoch_tr_NPV,epoch_te_loss, epoch_te_accuracy, epoch_te_MCC, epoch_te_SE, epoch_te_SPC,epoch_te_PPV,epoch_te_F1,epoch_te_NPV= fit(model, optimizer, train_dl, test_dl)\n",
    "    tr_loss.append(epoch_tr_loss)\n",
    "    tr_accuracy.append(epoch_tr_accuracy)\n",
    "    tr_MCC.append(epoch_tr_MCC)\n",
    "    tr_SE.append(epoch_tr_SE)\n",
    "    tr_SPC.append(epoch_tr_SPC)\n",
    "    tr_PPV.append(epoch_tr_PPV)\n",
    "    tr_NPV.append(epoch_tr_NPV)\n",
    "    tr_F1.append(epoch_tr_F1)\n",
    "    \"tr_AUC.append(epoch_tr_AUC)\"\n",
    "    \n",
    "    te_loss.append(epoch_te_loss)\n",
    "    te_accuracy.append(epoch_te_accuracy)\n",
    "    print(epoch_te_accuracy)\n",
    "    te_MCC.append(epoch_te_MCC)\n",
    "    te_SE.append(epoch_te_SE)\n",
    "    te_SPC.append(epoch_te_SPC)\n",
    "    te_PPV.append(epoch_te_PPV)\n",
    "    te_NPV.append(epoch_te_NPV)\n",
    "    te_F1.append(epoch_te_F1)\n",
    "    \"te_AUC.append(epoch_te_AUC)\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785589e",
   "metadata": {},
   "source": [
    "## 13.整理训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c416d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['loss', 'accuracy', 'MCC', 'SE', 'SPC', 'PPV', 'NPV','F1']\n",
    "\n",
    "tr_loss = pd.Series(tr_loss)\n",
    "tr_accuracy = pd.Series(tr_accuracy)\n",
    "tr_MCC = pd.Series(tr_MCC)\n",
    "tr_SE = pd.Series(tr_SE)\n",
    "tr_SPC = pd.Series(tr_SPC)\n",
    "tr_PPV = pd.Series(tr_PPV)\n",
    "tr_NPV = pd.Series(tr_NPV)\n",
    "tr_F1 = pd.Series(tr_F1)\n",
    "\n",
    "tr_result = pd.concat([tr_loss, tr_accuracy, tr_MCC, tr_SE, tr_SPC, tr_PPV, tr_NPV,tr_F1], axis=1)\n",
    "tr_result.columns = column_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cfef0",
   "metadata": {},
   "source": [
    "## 14.整理测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ac49b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['loss', 'accuracy', 'MCC', 'SE', 'SPC', 'PPV', 'NPV','F1']\n",
    "\n",
    "te_loss = pd.Series(te_loss)\n",
    "te_accuracy = pd.Series(te_accuracy)\n",
    "te_MCC = pd.Series(te_MCC)\n",
    "te_SE = pd.Series(te_SE)\n",
    "te_SPC = pd.Series(te_SPC)\n",
    "te_PPV = pd.Series(te_PPV)\n",
    "te_NPV = pd.Series(te_NPV)\n",
    "te_F1= pd.Series(te_F1)\n",
    "\n",
    "te_result = pd.concat([te_loss, te_accuracy, te_MCC, te_SE, te_SPC, te_PPV, te_NPV,te_F1], axis=1)\n",
    "te_result.columns = column_name\n",
    "# te_result.index = [*range(1, epochs + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae7925",
   "metadata": {},
   "source": [
    "## 15.输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7eda3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6966666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(te_result.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10808812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "tr_result.to_csv(r'./调参前后/Word_embedding_LSTMBI_train_result.csv')\n",
    "te_result.to_csv(r'./调参前后/Word_embedding_LSTMBI_valid_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3864e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
